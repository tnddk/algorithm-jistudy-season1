# 이진탐색
## 개요

이진 탐색 알고리즘은 **정렬된 리스트**에서 특정한 값의 위치를 찾는 알고리즘으로 **O(logN)**의 시간 복잡도를 갖는다.

## 개념

1. target값과 정렬된 리스트(첫 번째 인덱스 : LOW, 마지막 인덱스 : HIGH)의 중간 인덱스(MID)에 해당하는 값을 비교한다.
2. target값이 더 크다면 정렬된 리스트의 MID를 LOW로 변경하여 다시 새로운 MID에 해당하는 값과 target을 비교한다.
3. target값이 더 작다면 정렬된 리스트의 MID를 HIGH로 변경하여 다시 새로운 MID에 해당하는 값과 target을 비교한다.
4. target값과 MID에 해당하는 값이 같다면 MID를 반환한다.
5. 종료조건(HIGH ≤ LOW)이 되면 탐색 실패

### 예시 코드

```python
def binary_search_using_iteration(lst, target):
	LOW, HIGH = 0, len(lst)
	MID = (LOW+HIGH)//2
	while HIGH>LOW:
		if lst[MID]==target:
			return MID
		elif lst[MID] < target:
			HIGH = MID
		else:
			LOW = MID
    return -1

def binary_search_using_recur(lst, target, LOW, HIGH):
	if LOW > HIGH : return -1
	MID = (LOW+HIGH)//2
	if lst[MID] < target:
		return binary_search_using_recur(lst, target, LOW, MID-1)
	elif lst[MID] > target:
		return binary_search_using_recur(lst, target, MID+1, HIGH)
	else:
		return mid
```

### 파이썬 이진탐색 라이브러리 : bisect

- `bisect.bisect_left(sorted_list,target)`
    - 정렬된 리스트에서 target이 처음 나오는 위치
- `bisect.bisect_right(sorted_list, target)`
    - 정렬된 리스트에서 target이 마지막 나오는 위치 +1

```python
from bisect import bisect_left, bisect_right
sorted_list = [1, 2, 3, 3, 4, 5]
target = 3

left_target_idx = bisect_left(sorted_list, target) # 2 반환
right_target_idx = bisect_right(sorted_list, target) # 4 반환

# 정렬된 리스트에서 특정 값이 몇 번 등장하는지 확인
right_target_idx - left_target_idx
```
# O(NlogN) 정렬
## 합병정렬
### 개요

분할 정복 알고리즘 중 하나로 안정 정렬에 속해 입력 데이터가 무엇이든 시간 복잡도는 O(Nlog2N).

하나의 리스트를 두 개의 균등한 크기로 **분할**하고, 분할된 부분 리스트를 **정렬**한 다음, 부분 정렬 리스트를 **합하여** 전체가 정렬된 리스트가 되게 하는 방법

### 장점

- 입력 데이터가 무엇이든 간에 정렬되는 시간은 동일하다(안정적인 정렬).

### 단점

- 제자리 정렬(in-place sorting)이 아니기 때문에 레코드를 배열(Array)로 구성하면, 임시 배열이 필요하다.
- 레코드의 크기가 큰 경우 이동 횟수가 많아 매우 큰 시간적 낭비를 초래한다.

### 개념

![image](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/482ba5a1-281c-465f-bd10-1efbd3e0a9e1/Untitled.png)

- 합병 정렬의 단계
    1. 분할(Divide) : 가장 작은 단위(원소 1개)가 될 때까지 입력 배열을 2 개의 부분 배열로 분할한다. 
    2. 정복(Conquer) 및 결합(Combine) : 부분 배열을 정렬하면서 결합한다.
        - 두 개의 부분 배열을 각각 left, right라고 하면
        - (2-1)각각의 첫 번째 원소부터 비교후 더 작은 쪽의 원소를 새로운 배열에 결합
            - 해당 부분 배열의 인덱스만 증가시킨다.
        - (2-2)한쪽의 부분 배열의 처리가 끝나면 반대쪽 부분 배열의 남은 부분을 일괄 결합한다.

### 예시 코드

```python
def merge_sort(lst): # 1
    if len(lst) <= 1:
        return lst

    mid = len(lst)//2
    left = merge_sort(lst[:mid])
    right = merge_sort(lst[mid:])

    return merge(left, right) # 2

def merge(left, right):
    sorted_list = []
    i, j = 0, 0

		# 2-1
    while (i < len(left)) and (j < len(right)):
        if left[i] < right[j]:
            sorted_list.append(left[i])
            i += 1
        else:
            sorted_list.append(right[j])
            j += 1

		# 2-2
    if i < len(left):
        sorted_list += left[i:]
    if j < len(right):
        sorted_list += right[j:]

    return sorted_list
```
## 힙 정렬(Heap Sort)
### 개요

- 힙(HEAP) 자료구조의 특성을 활용한 정렬 방법
    - 힙은 완전 이진트리의 일종으로, 여러 값 중에서 최소, 최대값을 빠르게 찾기 위해 설계된 자료구조이다.
    - 최대 힙(Max Heap) : 부모 노드의 키 값이 자식 노드의 키 값보다 큰 힙 → 루트에 max
    - 최소 힙(Min Heap) : 부모 노드의 키 값이 자식 노드의 키 값보다 작은 힙 → 루트에 min
    
    ![image](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/09514942-6d5f-447f-ab55-ad76dad76e7f/Untitled.png)
    
- 이진 탐색 트리(Binary Search Tree)와는 다르다
    - 이진 탐색 트리는 이진 트리라는 점에서 공통점을 가지지만 최대 힙, 최소 힙과 다르게 right > mid > left로 노드가 배치된다.
    
    ![image](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/21aa8187-3631-4334-8a45-9a34489e9188/Untitled.png)
    

### 장점

- 항상 시간 복잡도 O(NlogN)을 보장한다.
- 힙에서 max or min을 구할 때 시간 복잡도는 O(1)이다.

### 단점

- 일반적으로 속도만 놓고 봤을 때 퀵 정렬이 더 빨라 잘 사용하지 않는다.

### 개념

1. 정렬하고자 하는 배열을 힙으로 만든다(`heapify` & `bulid heap`)
    - 힙은 완전 이진트리 성질을 만족하기 때문에 다음처럼 1차원 배열(array)로도 표현이 가능하다.
        
        ![image](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/22c7bfa0-2436-46c3-a618-686f1339ab4b/Untitled.png)
        
        ```python
        left_index = 2 * index + 1
        right_index = 2 * index + 2
        ```
        
    - 주어진 자료구조에서 힙 성질을 만족하도록 하는 연산을 `heapify`라고 한다.
        
        ```python
        def heapify(unsorted_list, index, heap_size):
        
        	# root 및 자식 인덱스 지정
        	largest = index
        	left_index = 2 * index + 1
        	right_index = 2 * index + 2
        
        	# root보다 왼쪽 자식이 더 큰 경우 교환
        	if left_index < heap_size and unsorted_list[left_index] > unsorted_list[largest]:
        		largest = left_index
        
        	# 오른쪽 자식이 더 큰 경우 교환
        	if right_index < heap_size and unsorted_list[right_index] > unsorted_list[largest]:
        		largest = right_index
        
        	# 실제 교환 수행하고 교환된 부분부터 다시 heapify(교환 후에도 힙 성질은 만족하는 지 검사)
        	if largest != index:
        		unsorted_list[largest], unsorted_list[index] = unsorted_list[index], unsorted_list[largest]
        		heapify(unsorted_list, largest, heap_size)
        ```
        
        - heapify는 최악의 경우 루트노드에서 잎새노드까지 값을 비교해야 하므로 트리의 높이($h=log_2N$)에 의존하며, 값을 비교하거나 바꾸는 연산은 O(1)이므로 heapify의 시간복잡도는 O(logN)이 된다.
        - `insert` 연산 시 heapify에서 부모노드와만 비교해도 됨(기존 형제 노드는 부모 노드보다 작다는게 보장되어있음) → O(logN)
        - `delete` 연산 시 root를 지우고 가장 마지막 값을 root로 위치시킨 후 heapify → O(logN)
    - heapify 연산으로 비어있는 리스트에 최대 힙 구성시 N개의 노드 각각 heapify를 수행하게 되므로 시간복잡도는 O(NlogN)이지만, **이진트리의 성질에 의해 배열의 중간 인덱스부터 위로 heapify를 수행해도 모든 요소 값을 한 번씩 비교할 수 있게 된다. (중간 인덱스부터 자식 노드가 있음)**
        - unsorted_list로 이진 트리 구성
            - 엣지 노드의 depth를 d라고 할 때 d인 노드 수는 n/2
            - d-1인 노드 수는 n/4, d-2인 노드 수는 n/8 …
            - 각 노드들은 heapify시 최악의 경우 교환을 자식 노드 수 만큼 한다.
        - 따라서 bulid heap의 시간 복잡도는
            
            ![image](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/46f5cfee-62c2-4b27-8982-8e794ed73850/Untitled.png)
            
2. 최대 힙의 루트노드(최대값; 배열의 첫번째요소)와 말단노드(배열의 마지막 요소)를 교환한다. 이때 최대값을 마지막에 고정한다. → O(logn)
3. 새 루트 노드에 대해 최대 힙을 구성한다.
4. 원소 개수 만큼 2와 3을 반복 수행한다. → O(n)
    
    
    $\therefore O(n) + O(logn) \cdot O(n) = O(nlogn)$
    

### heap sort 예시 코드

```python
def heap_sort(unsorted_list):
	n = len(unsorted_list)
	# 1
	for i in range(n//2-1, -1, -1):
		heapify(unsorted_list, i, n)
	
	# 2~4
	for i in range(n-1, 0, -1):
		unsorted_list[0], unsorted_list[i] = unsorted_list[i], unsorted_list[0]
		heapify(unsorted_list, 0, i) # 최대값 마지막 고정
	return unsorted_list
```

### python heapq 라이브러리

```python
import heapq

def heapsort(iterable):
	heap = []
	result = []
	
	# 모든 원소를 차례대로 힙에 삽입
	for value in iterable:
		heapq.heappush(heap, value)

	# 힙에 삽입된 모든 원소를 차례대로 꺼내어 담기 -> 항상 제일 작은 원소
	while heap:
		result.append(heapq.heappop(heap))

	return result
```

- 해당 라이브러리의 heap은 최소 힙으로 전부 삽입했다 빼면 오름차순 정렬이 된다.
- 삽입할 때 변수 앞에 `-`를 붙히고 뺄 때 다시 `-`를 붙이는 방법으로 내림차순 정렬이 가능하다.
- heapq는 다익스트라 최단 경로 알고리즘을 포함해 다양한 알고리즘에서 **우선순위 큐** 기능을 구현하고자 할 때 사용된다. heapq 외에도 priorityQueue 라이브러리를 사용할 수 있지만, 코딩 테스트 환경에서는 보통 heapq가 더 빠르게 동작한다.

## 퀵 정렬(Quick Sort)
## 개요

- 분할 정복 기법 및 재귀 알고리즘을 활용한 정렬 알고리즘
- 파이썬의 `list.sort()` 함수나 자바의 `Arrays.sort()` 같은 내장 정렬 함수는 대부분 퀵 정렬을 기본으로 한다.
- 병합 정렬과 유사해보이지만 내부적으로 정렬을 하는 방식에 있어서 큰 차이
    - 병합 정렬은 항상 정 중앙을 기준으로 단순 분할 후 병합 시점에서 값의 비교 연산이 일어남
    - 퀵 정렬은 분할 시점부터 비교 연산이 일어나기 때문에 이후 병합에 들어가는 비용이 매우 적거나 구현 방법에 따라 병합을 하지 않을 수도 있음
- 데이터 분포 및 pivot 값을 어떻게 선택하느냐에 따라 복잡도가 달라짐 → 불안정 정렬
    - **이상적인 경우 O(NlogN)의 시간 복잡도를 가진다.**
    - 상용 코드에서는 중앙값(median)에 가까운 pivot 값을 선택할 수 있는 전략이 요구되며, 배열의 **첫 값, 중앙값, 마지막값 중에 크기가 중간인 값을 사용**하는 방법이 많이 사용됨

## 장점

- 불필요한 데이터의 이동을 줄이고 먼 거리의 데이터를 교환할 수 있을 뿐 아니라, 한 번 결정된 피벗들이 연산에서 제외되는 특성 때문에 O(NlogN)의 시간복잡도를 가지는 다른 정렬 알고리즘과 비교했을 때 가장 빠르다 → 평균적으로 가장 빠른 알고리즘
- 정렬하고자 하는 배열 안에소 교환하는 방식, 다른 메모리 공간을 필요로 하지 않는다.

## 단점

- 불안정 정렬(Unstable Sort)이다.
- 정렬된 배열에 대해서는 불 균형 분할에 의해 수행 시간이 더 많이 걸린다.

## 개념

1. 피벗 설정
2. 피벗 기준으로 작은 값을 왼쪽, 큰 값을 오른쪽으로 이동
3. 피벗 고정, 피벗 기준 양쪽 분할
4. 양쪽 분할된 리스트에서 1-3 실행 → 정렬 완료

### 퀵 정렬 예시 코드

```python
def quick_sort(arr):
    def sort(low, high):
        if high <= low:
            return
        mid = partition(arr, low, high)
        sort(low, mid - 1)
        sort(mid, high)

    def partition(arr, low, high):
        pivot = arr[(low + high) // 2]  # 가운데 값 피벗 설정
        while low <= high:
            while arr[low] < pivot:
                low += 1
            while arr[high] > pivot:
                high -= 1
            if low <= high:
                arr[low], arr[high] = arr[high], arr[low]
                low, high = low + 1, high - 1
        return low

    return sort(0, len(arr)-1)

arr = [1, 3, 2, 4, 5]
quick_sort(arr)
print(arr)
```

## 카운팅 정렬(Counting Sort)
## 개요

- 배열에 존재하는 수의 개수를 세어주고, 이 정보를 바탕으로 정렬을 수행한다.
- 계수 정렬은 O(n+k)의 시간 복잡도를 갖는다.
    - k는 정렬을 수행할 배열의 가장 큰 값
    - k가 n보다 작다면 정렬의 수행 시간은 O(n)이 되겠지만, 무한대로 크다면 정렬의 수행 시간도 무한대가 된다.
- 수와 카운트는 배열 or 딕셔너리의 인덱스와 값을 통해서 기록할 수 있다.

### 배열을 이용한 방식

1. 배열에 존재하는 값 각각의 개수를 세어줄 count 배열을 만든다.
    
    ```python
    # 정렬을 수행할 배열
    arr = [4, 7, 9, 1, 3, 5, 2, 3, 4]
    
    count = [0] * (max(arr) + 1)
    
    for num in arr:
        count[num] += 1
        
    print(count)
    
    # [0, 1, 1, 2, 2, 1, 0, 1, 0, 1]
    ```
    
    - count[i]는 숫자 i가 배열에 몇 개 존재하는지에 대한 정보
2. count 배열의 원소를 누적합 값으로 갱신한다.
    
    ```python
    for i in range(1, len(count)):
        count[i] += count[i-1]
    
    print(count)
    
    # [0, 1, 2, 4, 6, 7, 7, 8, 8, 9]
    ```
    
3. arr의 원소를 정렬된 위치에 삽입할 arr의 길이와 같은 result 배열을 만들어준다. 
4. arr 각 원소의 값을 count의 인덱스로 사용해서 값을 가져와 이를 result의 인덱스로 사용해 arr의 원소로 저장한다. 
5. count[arr[i]]의 값을 1 줄여준다.
    
    ```python
    result = [0] * (len(arr))
    
    for num in arr:
    	idx = count[num]
    	result[idx-1] = num
    	count[num] -= 1
    
    print(result)
    # [1, 2, 3, 3, 4, 4, 5, 7, 9]
    ```
    

### 딕셔너리를 사용한 방식

- 배월의 원소 - 개수 관계를 key와 value쌍으로 나타낼 수 있다.
    
    ```python
    arr = [4, 7, 9, 1, 3, 5, 2, 3, 4]
    
    count_dict = {i:j for i, j in zip(arr, [arr.count(k) for k in arr])}
    result = []
    
    for num in range(max(arr)+1):
    	while num in count_dict and count_dict[num] != 0:
    		result.append(num)
    		count_dict[num] -= 1
    
    print(result)
    ```
    

### 장점

- k가 작으면 시간 복잡도가 O(N)에 가깝다.

### 단점

- k가 매우 클 때 메모리를 매우 비효율적으로 쓰게된다.
- 별도의 count, result배열을 만들어야 한다.
- 배열에 음수가 존재한다면 사용할 수 없다.(count 배열의 인덱스를 통해서 숫자의 개수를 세어주는 방식)